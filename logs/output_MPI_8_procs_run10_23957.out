Sender: LSF System <lsfadmin@node3.kepler.hpc.local>
Subject: Job 23957: <MPI_8_procs_run10> in cluster <kepler.lsf.hpc.local> Exited

Job <MPI_8_procs_run10> was submitted from host <mgr.kepler.hpc.local> by user <malkovsin.gmail.com> in cluster <kepler.lsf.hpc.local> at Thu May 29 19:57:31 2025
Job was executed on host(s) <8*node3.kepler.hpc.local>, in queue <normal>, as user <malkovsin.gmail.com> in cluster <kepler.lsf.hpc.local> at Thu May 29 20:03:04 2025
</home/malkovsin.gmail.com> was used as the home directory.
</home/malkovsin.gmail.com/Documents/newlab3> was used as the working directory.
Started at Thu May 29 20:03:04 2025
Terminated at Thu May 29 20:03:05 2025
Results reported at Thu May 29 20:03:18 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -J MPI_8_procs_run10
#BSUB -W 00:10
#BSUB -n 8
#BSUB -R "span[ptile=8]"
#BSUB -o logs/output_MPI_8_procs_run10_%J.out
#BSUB -e logs/error_MPI_8_procs_run10_%J.err
#BSUB -M 2GB

module load mpi/openmpi-x86_64
mpirun --bind-to core --map-by core ./exp_mpi

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited.


The output (if any) follows:



PS:

Unable to read stderr data from stderr buffer file; your job was probably aborted prematurely.

