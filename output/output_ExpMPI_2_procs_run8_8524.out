Sender: LSF System <lsfadmin@node5.kepler.hpc.local>
Subject: Job 8524: <ExpMPI_2_procs_run8> in cluster <kepler.lsf.hpc.local> Exited

Job <ExpMPI_2_procs_run8> was submitted from host <mgr.kepler.hpc.local> by user <malkovsin.gmail.com> in cluster <kepler.lsf.hpc.local> at Sat May 10 22:44:18 2025
Job was executed on host(s) <2*node5.kepler.hpc.local>, in queue <normal>, as user <malkovsin.gmail.com> in cluster <kepler.lsf.hpc.local> at Sat May 10 22:44:21 2025
</home/malkovsin.gmail.com> was used as the home directory.
</home/malkovsin.gmail.com/Documents/lab3> was used as the working directory.
Started at Sat May 10 22:44:21 2025
Terminated at Sat May 10 22:44:36 2025
Results reported at Sat May 10 22:44:36 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -J ExpMPI_2_procs_run8
#BSUB -W 00:05
#BSUB -n 2
#BSUB -R "span[ptile=2]"
#BSUB -o logs/output_ExpMPI_2_procs_run8_%J.out
#BSUB -e logs/error_ExpMPI_2_procs_run8_%J.err
#BSUB -M 512MB

module load mpi/openmpi-x86_64
mpirun --bind-to core --map-by core ./exp_mpi

------------------------------------------------------------

Exited with exit code 139.

Resource usage summary:

    CPU time :                                   4.00 sec.
    Max Memory :                                 502 MB
    Average Memory :                             346.00 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              19
    Max Threads :                                51
    Run time :                                   14 sec.
    Turnaround time :                            18 sec.

The output (if any) follows:



PS:

Read file <logs/error_ExpMPI_2_procs_run8_8524.err> for stderr output of this job.

